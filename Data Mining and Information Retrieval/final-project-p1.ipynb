{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise: Computational Linguistics over Reddit Data\n",
    "\n",
    "For this project we are going to ingest Reddit posts, process the data and perform computational linguistics over the Reddit posts.\n",
    "\n",
    "This project will build off of some work you have previously done. However, beyond that exercise of processing and cataloging the feeds, in this instance you will access the referenced Reddit post and perform computational linguistics over the post itself.\n",
    "\n",
    "![DataScraper_To_NLP.png MISSING](../images/DataScraper_To_NLP.png)\n",
    "\n",
    "---\n",
    "\n",
    "### From the site:\n",
    "\n",
    "reddit: https://www.reddit.com/  \n",
    "Reddit gives you the best of the Internet in one place. Get a constantly updating feed of breaking news, fun stories, pics, memes, and videos just for you.\n",
    "\n",
    "\n",
    "### From Wikipedia:\n",
    "Reddit is an American social news aggregation, web content rating, and discussion website. \n",
    "Registered members submit content to the site such as links, text posts, and images, \n",
    "which are then voted up or down by other members. \n",
    "Posts are organized by subject into user-created boards called \"subreddits\", \n",
    "which cover a variety of topics including news, science, movies, video games, music, books, fitness, food, and image-sharing. \n",
    "Submissions with more up-votes appear towards the top of their subreddit and, if they receive enough votes, ultimately on the site's front page. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Posting:\n",
    "\n",
    "The below link is an example post from someone that was tinkering with sentiment analysis; specifically they looked at the text of [Moby Dick](https://en.wikipedia.org/wiki/Moby-Dick).\n",
    "\n",
    "**Spoiler:** The conclusion was that the book is rather negative in sentiment.\n",
    "It is after all, about vengeance!\n",
    "\n",
    "https://www.reddit.com/r/LanguageTechnology/comments/9whk23/a_simple_nlp_pipeline_to_calculate_running/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From: https://www.redditinc.com/\n",
    "![REDDIT_About.png MISSING](../images/REDDIT_About_latest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Acquisition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Example Code:\n",
    "\n",
    "In this exercise, we will be using Reddit API for fetching the latest messages. We can also fetch recent posts from Reddit using web feeds (check [here](./rss-feeds.ipynb)), but it seems our IP got banned for excessive requests to Reddit over the last few days. So we will be using Reddit API for which you are required to create your Reddit account and an app. \n",
    "\n",
    "Follow [this article](https://gilberttanner.com/blog/scraping-redditdata) to create your credentials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Reddit API\n",
    "\n",
    "For fetching Reddit data using API, we will be using a Python wrapper to Reddit API: [PRAW: The Python Reddit API Wrapper](https://github.com/praw-dev/praw)\n",
    "\n",
    "Documentation: https://praw.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(client_id='PrBMPq2EXVy9ShqE3RFeeA', \n",
    "                     client_secret='oRzCf-3oLpnfc7Z9ZDC_Vx9Gjr_iHA', \n",
    "                     user_agent='WebScraping')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 hot posts from the MachineLearning subreddit\n",
    "hot_posts = reddit.subreddit('datascience').hot(limit=10)  # hot posts\n",
    "\n",
    "new_posts = reddit.subreddit('datascience').new(limit=10)  # new posts\n",
    "\n",
    "# get hottest posts from all subreddits\n",
    "hot_posts = reddit.subreddit('all').hot(limit=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts = list(hot_posts)  \n",
    "\n",
    "# this line will initiate the fetching of posts as PRAW use a lazy approach (i.e, fetch when required)\n",
    "# this part is done to avoid calling Reddit API multiple times while developing our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for post in all_posts:\n",
    "    print(f\"id : {post.id}\")\n",
    "    print(f\"title : {post.title}\")\n",
    "    print(f\"url : {post.url}\")\n",
    "    print(f\"author : {str(post.author)} {type(str(post.author))}\")\n",
    "    print(f\"score : {post.score} {type(post.score)} \")\n",
    "    print(f\"subreddit : {post.subreddit} {type(post.subreddit)} \")\n",
    "    print(f\"num_comments : {post.num_comments}\")\n",
    "    print(f\"body : {post.selftext}\")\n",
    "    print(f\"created : {post.created}\")\n",
    "    print(f\"link_flair_text : {post.link_flair_text}\")\n",
    "    break  # break the loop after printing information about the first post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-Reddits\n",
    "\n",
    "As described above, sub-reddits are communities organized around particular topics.\n",
    "\n",
    "Some example sub-reddits:\n",
    " * https://www.reddit.com/r/datascience/\n",
    " * https://www.reddit.com/r/MachineLearning/\n",
    " * https://www.reddit.com/r/LanguageTechnology/\n",
    " * https://www.reddit.com/r/NLP/\n",
    " * https://www.reddit.com/r/Python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Tasks\n",
    "\n",
    "## Part I: Data Acquisition and Loading \n",
    "1. Choose a subreddit of your choice. Preferably something of interest to you. \n",
    "1. Conceptualize a database design that can collect the data.\n",
    "    * Make sure your items (posts) are unique and not duplicated!\n",
    "    * Make sure you capture at least title, author, subreddit, tags, title link, and timestamp\n",
    "    * Along with the metadata, capture all the text into one or more data field(s) suitable for information retrieval\n",
    "    * Write triggers for auto updates of IR related fields\n",
    "    * Add index (either GIN or GiST) for the IR related fields\n",
    "    * Additionally, design a field to hold:\n",
    "        * Sentiment\n",
    "1. Implement the database in your PostgreSQL schema\n",
    "1. Implement cells of Python Code that \n",
    "    * collect the latest posts from a subreddit of your choice (**should be text-dominant not image/video**) and collect at least 500 posts (if possible), \n",
    "    * processes the messages to extract metadata, \n",
    "    * process the text for IR, and \n",
    "    * perform computational linguistics (i.e, extract sentiment scores), \n",
    "    * then insert the data into your database.\n",
    "1. After you have loaded data from a subreddit, choose a few more subreddits and load those!\n",
    "\n",
    "## Part II: Analytics \n",
    "\n",
    "1. Write some test queries following the text vectors from Module 7.\n",
    "1. Produce **interesting visualizations** of the linguistic data.\n",
    "    * Try to look for trends (within a subreddit) and and variations of topics across subreddits\n",
    "    * Some comparative plots across feeds\n",
    "1. Write a summary of your findings!\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Data Acquisition and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Design your database\n",
    "\n",
    "Conceptualize a database design that can collect the data.\n",
    "* Make sure your items (posts) are unique and not duplicated!\n",
    "* Make sure you capture at least title, link, author, subreddit, tag/flair, and timestamp\n",
    "* Capture all the body text into fields suitable for information retrieval\n",
    "* Write triggers for auto updates of IR related fields\n",
    "* Add index (either GIN or GiST) for the IR related fields\n",
    "* Additionally, design a field to hold:\n",
    "    - Sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your Design here. You can describe your design with text or picture\n",
    "## ---------------------------------------------------------------------------\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='design.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Task 2: Implement the database in your PostgreSQL schema\n",
    "\n",
    "You can choose any of the three ways to implement your database. \n",
    "\n",
    "* sql magic \n",
    "* sql terminal \n",
    "* psycopg2 or sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Password and hit enter········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "# Initialize some variables\n",
    "mysso= 'kg37m'\n",
    "schema= 'kg37m'\n",
    "hostname='pgsql.dsa.lan'\n",
    "database='dsa_student'\n",
    "\n",
    "mypasswd = getpass.getpass(\"Type Password and hit enter\")\n",
    "connection_string = f\"postgres://{mysso}:{mypasswd}@{hostname}/{database}\"\n",
    "\n",
    "%load_ext sql\n",
    "%sql $connection_string \n",
    "\n",
    "# Then remove the password from computer memory\n",
    "del mypasswd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://kg37m:***@pgsql.dsa.lan/dsa_student\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "-------------------------\n",
    "-- create table\n",
    "-------------------------\n",
    "\n",
    "DROP TABLE IF EXISTS posts;\n",
    "\n",
    "CREATE TABLE posts(\n",
    "        id varchar(20) NOT NULL,\n",
    "        title varchar(500) NOT NULL,\n",
    "        url text NOT NULL,\n",
    "        author varchar(100) NOT NULL,\n",
    "        subreddit varchar(50) NOT NULL,\n",
    "        timestamp TIMESTAMP NOT NULL,\n",
    "        flair varchar(50),\n",
    "        points INT NOT NULL,\n",
    "        comments INT NOT NULL,\n",
    "        text text NOT NULL,\n",
    "        sentiment varchar(3) NOT NULL\n",
    ");\n",
    "\n",
    "ALTER TABLE posts\n",
    "ADD CONSTRAINT pk_posts PRIMARY KEY (id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## index and triggers added later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Implement cells of Python Code that\n",
    "\n",
    "* collect the latest posts from a subreddit of your choice (should be text-dominant not image/video) and collect at least 500 posts (if possible),\n",
    "* processes the messages to extract id, title, link, author, subreddit, tag/flair, timestamp, etc. \n",
    "* process the text for IR, and\n",
    "* perform computational linguistics (e.g., get sentiment scores)\n",
    "* then insert the data into your database.\n",
    "\n",
    "\n",
    "Notes: \n",
    "* Each call to Reddit API returns 100 entries max. If we set a limit of more than 100, PRAW will handle multiple API calls internally and lazily fetches data. Check obfuscation and API limitation in https://praw.readthedocs.io/en/v3.6.2/pages/getting_started.html. \n",
    "* Develop and test your code with less than 100 messages from a subreddit. Then increase the limit and add few more subreddits. \n",
    "* While loading the table, test with one row \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code in this cell\n",
    "## ------------------------\n",
    "\n",
    "## import praw and fill reddit crawler info\n",
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(client_id='PrBMPq2EXVy9ShqE3RFeeA', \n",
    "                     client_secret='oRzCf-3oLpnfc7Z9ZDC_Vx9Gjr_iHA', \n",
    "                     user_agent='WebScraping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q56pjd',\n",
       " 'Weekly Entering & Transitioning Thread | 10 Oct 2021 - 17 Oct 2021',\n",
       " 'https://www.reddit.com/r/datascience/comments/q56pjd/weekly_entering_transitioning_thread_10_oct_2021/',\n",
       " Redditor(name='datascience-bot'),\n",
       " Subreddit(display_name='datascience'),\n",
       " 1633867230.0,\n",
       " 'Discussion',\n",
       " 13,\n",
       " 90,\n",
       " \"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\\n\\n* Learning resources (e.g. books, tutorials, videos)\\n* Traditional education (e.g. schools, degrees, electives)\\n* Alternative education (e.g. online courses, bootcamps)\\n* Job search questions (e.g. resumes, applying, career prospects)\\n* Elementary questions (e.g. where to start, what next)\\n\\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and [Resources](Resources) pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrape data from Reddit to put in dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "posts_list = []\n",
    "subreddit = reddit.subreddit('datascience')\n",
    "\n",
    "for post in subreddit.hot(limit=500):\n",
    "    posts_list.append([post.id, post.title, post.url, post.author, post.subreddit, post.created, post.link_flair_text, post.score, post.num_comments, post.selftext])\n",
    "\n",
    "posts_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flair</th>\n",
       "      <th>points</th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q56pjd</td>\n",
       "      <td>Weekly Entering &amp; Transitioning Thread | 10 Oc...</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>datascience-bot</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.633867e+09</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "      <td>Welcome to this week's entering &amp; transitionin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q7zuxn</td>\n",
       "      <td>Putting ML models in production</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>Proletarian_Tear</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.634219e+09</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>What to consider when putting ML models in pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q85c4e</td>\n",
       "      <td>Ethical Dilema</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>Your_Data_Talking</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.634235e+09</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>I’ve been put into a conundrum and have an ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q80hcb</td>\n",
       "      <td>Any experienced data scientist or analyst look...</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>JS-AI</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.634221e+09</td>\n",
       "      <td>Career</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>I work at a healthcare tech company (SaaS), bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q844ek</td>\n",
       "      <td>ETL and ELT</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>KiwiD_1618</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.634231e+09</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Ok I mean I got it. I completely understand wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  q56pjd  Weekly Entering & Transitioning Thread | 10 Oc...   \n",
       "1  q7zuxn                    Putting ML models in production   \n",
       "2  q85c4e                                     Ethical Dilema   \n",
       "3  q80hcb  Any experienced data scientist or analyst look...   \n",
       "4  q844ek                                        ETL and ELT   \n",
       "\n",
       "                                                 url             author  \\\n",
       "0  https://www.reddit.com/r/datascience/comments/...    datascience-bot   \n",
       "1  https://www.reddit.com/r/datascience/comments/...   Proletarian_Tear   \n",
       "2  https://www.reddit.com/r/datascience/comments/...  Your_Data_Talking   \n",
       "3  https://www.reddit.com/r/datascience/comments/...              JS-AI   \n",
       "4  https://www.reddit.com/r/datascience/comments/...         KiwiD_1618   \n",
       "\n",
       "     subreddit     timestamp       flair  points  comments  \\\n",
       "0  datascience  1.633867e+09  Discussion      13        90   \n",
       "1  datascience  1.634219e+09  Discussion      50        28   \n",
       "2  datascience  1.634235e+09  Discussion       9        11   \n",
       "3  datascience  1.634221e+09      Career      10        11   \n",
       "4  datascience  1.634231e+09  Discussion       6         5   \n",
       "\n",
       "                                                text  \n",
       "0  Welcome to this week's entering & transitionin...  \n",
       "1  What to consider when putting ML models in pro...  \n",
       "2  I’ve been put into a conundrum and have an ide...  \n",
       "3  I work at a healthcare tech company (SaaS), bu...  \n",
       "4  Ok I mean I got it. I completely understand wh...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df = pd.DataFrame(posts_list, columns=['id', 'title', 'url', 'author', 'subreddit', 'timestamp', 'flair', 'points', 'comments', 'text'])\n",
    "\n",
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all posts unique\n",
    "posts_df = posts_df.drop_duplicates(subset=['id'])\n",
    "\n",
    "# format datetime\n",
    "posts_df['timestamp'] = pd.to_datetime(posts_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# clean text\n",
    "posts_df['text'] = [re.sub('[\\n]*','', p) for p in posts_df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to this week's entering &amp; transitionin...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.5093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What to consider when putting ML models in pro...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.7059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’ve been put into a conundrum and have an ide...</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.9349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I work at a healthcare tech company (SaaS), bu...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.9636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok I mean I got it. I completely understand wh...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.9638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post    neg    neu    pos  \\\n",
       "0  Welcome to this week's entering & transitionin...  0.000  0.963  0.037   \n",
       "1  What to consider when putting ML models in pro...  0.000  0.804  0.196   \n",
       "2  I’ve been put into a conundrum and have an ide...  0.114  0.840  0.046   \n",
       "3  I work at a healthcare tech company (SaaS), bu...  0.016  0.777  0.207   \n",
       "4  Ok I mean I got it. I completely understand wh...  0.000  0.860  0.140   \n",
       "\n",
       "   compound  \n",
       "0    0.5093  \n",
       "1    0.7059  \n",
       "2   -0.9349  \n",
       "3    0.9636  \n",
       "4    0.9638  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze sentiment\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "posts_sentiment = [analyzer.polarity_scores(p) for p in posts_df['text']]\n",
    "\n",
    "sentiment_df = pd.DataFrame(posts_sentiment)\n",
    "sentiment_df['post'] = posts_df['text']\n",
    "\n",
    "sentiment_df = sentiment_df[['post', 'neg', 'neu', 'pos', 'compound']]\n",
    "\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to this week's entering &amp; transitionin...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What to consider when putting ML models in pro...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’ve been put into a conundrum and have an ide...</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.9349</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I work at a healthcare tech company (SaaS), bu...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok I mean I got it. I completely understand wh...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post    neg    neu    pos  \\\n",
       "0  Welcome to this week's entering & transitionin...  0.000  0.963  0.037   \n",
       "1  What to consider when putting ML models in pro...  0.000  0.804  0.196   \n",
       "2  I’ve been put into a conundrum and have an ide...  0.114  0.840  0.046   \n",
       "3  I work at a healthcare tech company (SaaS), bu...  0.016  0.777  0.207   \n",
       "4  Ok I mean I got it. I completely understand wh...  0.000  0.860  0.140   \n",
       "\n",
       "   compound sentiment  \n",
       "0    0.5093       POS  \n",
       "1    0.7059       POS  \n",
       "2   -0.9349       NEG  \n",
       "3    0.9636       POS  \n",
       "4    0.9638       POS  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorize neutral/positive/negative \n",
    "sentiment_df['sentiment'] = 'NEU'\n",
    "sentiment_df.loc[sentiment_df['compound'] > 0.05, 'sentiment'] = 'POS'\n",
    "sentiment_df.loc[sentiment_df['compound'] < -0.05, 'sentiment'] = 'NEG'\n",
    "\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flair</th>\n",
       "      <th>points</th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q56pjd</td>\n",
       "      <td>Weekly Entering &amp; Transitioning Thread | 10 Oc...</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>datascience-bot</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.633867230</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "      <td>Welcome to this week's entering &amp; transitionin...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q7zuxn</td>\n",
       "      <td>Putting ML models in production</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>Proletarian_Tear</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634218550</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>What to consider when putting ML models in pro...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q85c4e</td>\n",
       "      <td>Ethical Dilema</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>Your_Data_Talking</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634235081</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>I’ve been put into a conundrum and have an ide...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q80hcb</td>\n",
       "      <td>Any experienced data scientist or analyst look...</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>JS-AI</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634220504</td>\n",
       "      <td>Career</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>I work at a healthcare tech company (SaaS), bu...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q844ek</td>\n",
       "      <td>ETL and ELT</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>KiwiD_1618</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634231460</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Ok I mean I got it. I completely understand wh...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  q56pjd  Weekly Entering & Transitioning Thread | 10 Oc...   \n",
       "1  q7zuxn                    Putting ML models in production   \n",
       "2  q85c4e                                     Ethical Dilema   \n",
       "3  q80hcb  Any experienced data scientist or analyst look...   \n",
       "4  q844ek                                        ETL and ELT   \n",
       "\n",
       "                                                 url             author  \\\n",
       "0  https://www.reddit.com/r/datascience/comments/...    datascience-bot   \n",
       "1  https://www.reddit.com/r/datascience/comments/...   Proletarian_Tear   \n",
       "2  https://www.reddit.com/r/datascience/comments/...  Your_Data_Talking   \n",
       "3  https://www.reddit.com/r/datascience/comments/...              JS-AI   \n",
       "4  https://www.reddit.com/r/datascience/comments/...         KiwiD_1618   \n",
       "\n",
       "     subreddit                     timestamp       flair  points  comments  \\\n",
       "0  datascience 1970-01-01 00:00:01.633867230  Discussion      13        90   \n",
       "1  datascience 1970-01-01 00:00:01.634218550  Discussion      50        28   \n",
       "2  datascience 1970-01-01 00:00:01.634235081  Discussion       9        11   \n",
       "3  datascience 1970-01-01 00:00:01.634220504      Career      10        11   \n",
       "4  datascience 1970-01-01 00:00:01.634231460  Discussion       6         5   \n",
       "\n",
       "                                                text sentiment  \n",
       "0  Welcome to this week's entering & transitionin...       POS  \n",
       "1  What to consider when putting ML models in pro...       POS  \n",
       "2  I’ve been put into a conundrum and have an ide...       NEG  \n",
       "3  I work at a healthcare tech company (SaaS), bu...       POS  \n",
       "4  Ok I mean I got it. I completely understand wh...       POS  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add sentiment to main dataframe\n",
    "posts_df['sentiment'] = sentiment_df['sentiment']\n",
    "\n",
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flair</th>\n",
       "      <th>points</th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q56pjd</td>\n",
       "      <td>Weekly Entering &amp; Transitioning Thread | 10 Oc...</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>datascience-bot</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.633867230</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "      <td>Welcome to this week's entering &amp; transitionin...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q7zuxn</td>\n",
       "      <td>Putting ML models in production</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>Proletarian_Tear</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634218550</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>What to consider when putting ML models in pro...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q85c4e</td>\n",
       "      <td>Ethical Dilema</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>Your_Data_Talking</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634235081</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>I’ve been put into a conundrum and have an ide...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q80hcb</td>\n",
       "      <td>Any experienced data scientist or analyst look...</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>JS-AI</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634220504</td>\n",
       "      <td>Career</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>I work at a healthcare tech company (SaaS), bu...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q844ek</td>\n",
       "      <td>ETL and ELT</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>KiwiD_1618</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634231460</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Ok I mean I got it. I completely understand wh...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  q56pjd  Weekly Entering & Transitioning Thread | 10 Oc...   \n",
       "1  q7zuxn                    Putting ML models in production   \n",
       "2  q85c4e                                     Ethical Dilema   \n",
       "3  q80hcb  Any experienced data scientist or analyst look...   \n",
       "4  q844ek                                        ETL and ELT   \n",
       "\n",
       "                                                 url             author  \\\n",
       "0  https://www.reddit.com/r/datascience/comments/...    datascience-bot   \n",
       "1  https://www.reddit.com/r/datascience/comments/...   Proletarian_Tear   \n",
       "2  https://www.reddit.com/r/datascience/comments/...  Your_Data_Talking   \n",
       "3  https://www.reddit.com/r/datascience/comments/...              JS-AI   \n",
       "4  https://www.reddit.com/r/datascience/comments/...         KiwiD_1618   \n",
       "\n",
       "     subreddit                     timestamp       flair  points  comments  \\\n",
       "0  datascience 1970-01-01 00:00:01.633867230  Discussion      13        90   \n",
       "1  datascience 1970-01-01 00:00:01.634218550  Discussion      50        28   \n",
       "2  datascience 1970-01-01 00:00:01.634235081  Discussion       9        11   \n",
       "3  datascience 1970-01-01 00:00:01.634220504      Career      10        11   \n",
       "4  datascience 1970-01-01 00:00:01.634231460  Discussion       6         5   \n",
       "\n",
       "                                                text sentiment  \n",
       "0  Welcome to this week's entering & transitionin...       POS  \n",
       "1  What to consider when putting ML models in pro...       POS  \n",
       "2  I’ve been put into a conundrum and have an ide...       NEG  \n",
       "3  I work at a healthcare tech company (SaaS), bu...       POS  \n",
       "4  Ok I mean I got it. I completely understand wh...       POS  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert author and subreddit to so parsable by sqlalchemy\n",
    "for i in range(len(posts_df)): \n",
    "    author_str = str(posts_df.at[i, 'author'])\n",
    "    posts_df.at[i, 'author'] = author_str\n",
    "    \n",
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flair</th>\n",
       "      <th>points</th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q56pjd</td>\n",
       "      <td>Weekly Entering &amp; Transitioning Thread | 10 Oc...</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>datascience-bot</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.633867230</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>13</td>\n",
       "      <td>90</td>\n",
       "      <td>Welcome to this week's entering &amp; transitionin...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q7zuxn</td>\n",
       "      <td>Putting ML models in production</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>Proletarian_Tear</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634218550</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>What to consider when putting ML models in pro...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q85c4e</td>\n",
       "      <td>Ethical Dilema</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>Your_Data_Talking</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634235081</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>I’ve been put into a conundrum and have an ide...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q80hcb</td>\n",
       "      <td>Any experienced data scientist or analyst look...</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>JS-AI</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634220504</td>\n",
       "      <td>Career</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>I work at a healthcare tech company (SaaS), bu...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q844ek</td>\n",
       "      <td>ETL and ELT</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>KiwiD_1618</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1970-01-01 00:00:01.634231460</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Ok I mean I got it. I completely understand wh...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  q56pjd  Weekly Entering & Transitioning Thread | 10 Oc...   \n",
       "1  q7zuxn                    Putting ML models in production   \n",
       "2  q85c4e                                     Ethical Dilema   \n",
       "3  q80hcb  Any experienced data scientist or analyst look...   \n",
       "4  q844ek                                        ETL and ELT   \n",
       "\n",
       "                                                 url             author  \\\n",
       "0  https://www.reddit.com/r/datascience/comments/...    datascience-bot   \n",
       "1  https://www.reddit.com/r/datascience/comments/...   Proletarian_Tear   \n",
       "2  https://www.reddit.com/r/datascience/comments/...  Your_Data_Talking   \n",
       "3  https://www.reddit.com/r/datascience/comments/...              JS-AI   \n",
       "4  https://www.reddit.com/r/datascience/comments/...         KiwiD_1618   \n",
       "\n",
       "     subreddit                     timestamp       flair  points  comments  \\\n",
       "0  datascience 1970-01-01 00:00:01.633867230  Discussion      13        90   \n",
       "1  datascience 1970-01-01 00:00:01.634218550  Discussion      50        28   \n",
       "2  datascience 1970-01-01 00:00:01.634235081  Discussion       9        11   \n",
       "3  datascience 1970-01-01 00:00:01.634220504      Career      10        11   \n",
       "4  datascience 1970-01-01 00:00:01.634231460  Discussion       6         5   \n",
       "\n",
       "                                                text sentiment  \n",
       "0  Welcome to this week's entering & transitionin...       POS  \n",
       "1  What to consider when putting ML models in pro...       POS  \n",
       "2  I’ve been put into a conundrum and have an ide...       NEG  \n",
       "3  I work at a healthcare tech company (SaaS), bu...       POS  \n",
       "4  Ok I mean I got it. I completely understand wh...       POS  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(posts_df)): \n",
    "    sub_str = str(posts_df.at[i, 'subreddit'])\n",
    "    posts_df.at[i, 'subreddit'] = sub_str\n",
    "    \n",
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe for visualizations in part two\n",
    "posts_df.to_csv('datascience.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to sql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "posts_df.to_sql('posts', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: After you have loaded data from a subreddit, choose a few more subreddit and load those!\n",
    "\n",
    "Add cells if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code in this cell\n",
    "## ------------------------\n",
    "\n",
    "# repeat process for MachineLearning\n",
    "\n",
    "# scrape data from Reddit to put in dataframe\n",
    "posts_list = []\n",
    "subreddit = reddit.subreddit('MachineLearning')\n",
    "\n",
    "for post in subreddit.hot(limit=500):\n",
    "    posts_list.append([post.id, post.title, post.url, post.author, post.subreddit, post.created, post.link_flair_text, post.score, post.num_comments, post.selftext])\n",
    "\n",
    "posts_df = pd.DataFrame(posts_list, columns=['id', 'title', 'url', 'author', 'subreddit', 'timestamp', 'flair', 'points', 'comments', 'text'])\n",
    "\n",
    "# make sure all posts unique\n",
    "posts_df.drop_duplicates(subset=['id'])\n",
    "\n",
    "# format datetime\n",
    "posts_df['timestamp'] = pd.to_datetime(posts_df['timestamp'])\n",
    "\n",
    "# clean text\n",
    "posts_df['text'] = [re.sub('[\\n]*','', p) for p in posts_df['text']]\n",
    "\n",
    "# analyze sentiment\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "posts_sentiment = [analyzer.polarity_scores(p) for p in posts_df['text']]\n",
    "\n",
    "sentiment_df = pd.DataFrame(posts_sentiment)\n",
    "sentiment_df['post'] = posts_df['text']\n",
    "\n",
    "sentiment_df = sentiment_df[['post', 'neg', 'neu', 'pos', 'compound']]\n",
    "\n",
    "# categorize neutral/positive/negative \n",
    "sentiment_df['sentiment'] = 'NEU'\n",
    "sentiment_df.loc[sentiment_df['compound'] > 0.05, 'sentiment'] = 'POS'\n",
    "sentiment_df.loc[sentiment_df['compound'] < -0.05, 'sentiment'] = 'NEG'\n",
    "\n",
    "# add sentiment to main dataframe\n",
    "posts_df['sentiment'] = sentiment_df['sentiment']\n",
    "\n",
    "# convert author and subreddit to strings so parsable by sqlalchemy\n",
    "for i in range(len(posts_df)): \n",
    "    author_str = str(posts_df.at[i, 'author'])\n",
    "    posts_df.at[i, 'author'] = author_str\n",
    "\n",
    "for i in range(len(posts_df)): \n",
    "    sub_str = str(posts_df.at[i, 'subreddit'])\n",
    "    posts_df.at[i, 'subreddit'] = sub_str\n",
    "\n",
    "# convert dataframe to sql\n",
    "posts_df.to_sql('posts', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# save for visualization\n",
    "posts_df.to_csv('machinelearning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat process for Python\n",
    "\n",
    "# scrape data from Reddit to put in dataframe\n",
    "posts_list = []\n",
    "subreddit = reddit.subreddit('Python')\n",
    "\n",
    "for post in subreddit.hot(limit=500):\n",
    "    posts_list.append([post.id, post.title, post.url, post.author, post.subreddit, post.created, post.link_flair_text, post.score, post.num_comments, post.selftext])\n",
    "\n",
    "posts_df = pd.DataFrame(posts_list, columns=['id', 'title', 'url', 'author', 'subreddit', 'timestamp', 'flair', 'points', 'comments', 'text'])\n",
    "\n",
    "# make sure all posts unique\n",
    "posts_df.drop_duplicates(subset=['id'])\n",
    "\n",
    "# format datetime\n",
    "posts_df['timestamp'] = pd.to_datetime(posts_df['timestamp'])\n",
    "\n",
    "# clean text\n",
    "posts_df['text'] = [re.sub('[\\n]*','', p) for p in posts_df['text']]\n",
    "\n",
    "# analyze sentiment\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "posts_sentiment = [analyzer.polarity_scores(p) for p in posts_df['text']]\n",
    "\n",
    "sentiment_df = pd.DataFrame(posts_sentiment)\n",
    "sentiment_df['post'] = posts_df['text']\n",
    "\n",
    "sentiment_df = sentiment_df[['post', 'neg', 'neu', 'pos', 'compound']]\n",
    "\n",
    "# categorize neutral/positive/negative \n",
    "sentiment_df['sentiment'] = 'NEU'\n",
    "sentiment_df.loc[sentiment_df['compound'] > 0.05, 'sentiment'] = 'POS'\n",
    "sentiment_df.loc[sentiment_df['compound'] < -0.05, 'sentiment'] = 'NEG'\n",
    "\n",
    "# add sentiment to main dataframe\n",
    "posts_df['sentiment'] = sentiment_df['sentiment']\n",
    "\n",
    "# convert author and subreddit to strings so parsable by sqlalchemy\n",
    "for i in range(len(posts_df)): \n",
    "    author_str = str(posts_df.at[i, 'author'])\n",
    "    posts_df.at[i, 'author'] = author_str\n",
    "\n",
    "for i in range(len(posts_df)): \n",
    "    sub_str = str(posts_df.at[i, 'subreddit'])\n",
    "    posts_df.at[i, 'subreddit'] = sub_str\n",
    "\n",
    "# convert dataframe to sql\n",
    "posts_df.to_sql('posts', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# save for visualization\n",
    "posts_df.to_csv('python.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat process for NLP\n",
    "\n",
    "# scrape data from Reddit to put in dataframe\n",
    "posts_list = []\n",
    "subreddit = reddit.subreddit('NLP')\n",
    "\n",
    "for post in subreddit.hot(limit=500):\n",
    "    posts_list.append([post.id, post.title, post.url, post.author, post.subreddit, post.created, post.link_flair_text, post.score, post.num_comments, post.selftext])\n",
    "\n",
    "posts_df = pd.DataFrame(posts_list, columns=['id', 'title', 'url', 'author', 'subreddit', 'timestamp', 'flair', 'points', 'comments', 'text'])\n",
    "\n",
    "# make sure all posts unique\n",
    "posts_df.drop_duplicates(subset=['id'])\n",
    "\n",
    "# format datetime\n",
    "posts_df['timestamp'] = pd.to_datetime(posts_df['timestamp'])\n",
    "\n",
    "# clean text\n",
    "posts_df['text'] = [re.sub('[\\n]*','', p) for p in posts_df['text']]\n",
    "\n",
    "# analyze sentiment\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "posts_sentiment = [analyzer.polarity_scores(p) for p in posts_df['text']]\n",
    "\n",
    "sentiment_df = pd.DataFrame(posts_sentiment)\n",
    "sentiment_df['post'] = posts_df['text']\n",
    "\n",
    "sentiment_df = sentiment_df[['post', 'neg', 'neu', 'pos', 'compound']]\n",
    "\n",
    "# categorize neutral/positive/negative \n",
    "sentiment_df['sentiment'] = 'NEU'\n",
    "sentiment_df.loc[sentiment_df['compound'] > 0.05, 'sentiment'] = 'POS'\n",
    "sentiment_df.loc[sentiment_df['compound'] < -0.05, 'sentiment'] = 'NEG'\n",
    "\n",
    "# add sentiment to main dataframe\n",
    "posts_df['sentiment'] = sentiment_df['sentiment']\n",
    "\n",
    "# convert author and subreddit to strings so parsable by sqlalchemy\n",
    "for i in range(len(posts_df)): \n",
    "    author_str = str(posts_df.at[i, 'author'])\n",
    "    posts_df.at[i, 'author'] = author_str\n",
    "\n",
    "for i in range(len(posts_df)): \n",
    "    sub_str = str(posts_df.at[i, 'subreddit'])\n",
    "    posts_df.at[i, 'subreddit'] = sub_str\n",
    "\n",
    "# convert dataframe to sql\n",
    "posts_df.to_sql('posts', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# save for visualization\n",
    "posts_df.to_csv('nlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat process for LanguageTechnology\n",
    "\n",
    "# scrape data from Reddit to put in dataframe\n",
    "posts_list = []\n",
    "subreddit = reddit.subreddit('LanguageTechnology')\n",
    "\n",
    "for post in subreddit.hot(limit=500):\n",
    "    posts_list.append([post.id, post.title, post.url, post.author, post.subreddit, post.created, post.link_flair_text, post.score, post.num_comments, post.selftext])\n",
    "\n",
    "posts_df = pd.DataFrame(posts_list, columns=['id', 'title', 'url', 'author', 'subreddit', 'timestamp', 'flair', 'points', 'comments', 'text'])\n",
    "\n",
    "# make sure all posts unique\n",
    "posts_df.drop_duplicates(subset=['id'])\n",
    "\n",
    "# format datetime\n",
    "posts_df['timestamp'] = pd.to_datetime(posts_df['timestamp'])\n",
    "\n",
    "# clean text\n",
    "posts_df['text'] = [re.sub('[\\n]*','', p) for p in posts_df['text']]\n",
    "\n",
    "# analyze sentiment\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "posts_sentiment = [analyzer.polarity_scores(p) for p in posts_df['text']]\n",
    "\n",
    "sentiment_df = pd.DataFrame(posts_sentiment)\n",
    "sentiment_df['post'] = posts_df['text']\n",
    "\n",
    "sentiment_df = sentiment_df[['post', 'neg', 'neu', 'pos', 'compound']]\n",
    "\n",
    "# categorize neutral/positive/negative \n",
    "sentiment_df['sentiment'] = 'NEU'\n",
    "sentiment_df.loc[sentiment_df['compound'] > 0.05, 'sentiment'] = 'POS'\n",
    "sentiment_df.loc[sentiment_df['compound'] < -0.05, 'sentiment'] = 'NEG'\n",
    "\n",
    "# add sentiment to main dataframe\n",
    "posts_df['sentiment'] = sentiment_df['sentiment']\n",
    "\n",
    "# convert author and subreddit to strings so parsable by sqlalchemy\n",
    "for i in range(len(posts_df)): \n",
    "    author_str = str(posts_df.at[i, 'author'])\n",
    "    posts_df.at[i, 'author'] = author_str\n",
    "\n",
    "for i in range(len(posts_df)): \n",
    "    sub_str = str(posts_df.at[i, 'subreddit'])\n",
    "    posts_df.at[i, 'subreddit'] = sub_str\n",
    "\n",
    "# convert dataframe to sql\n",
    "posts_df.to_sql('posts', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# save for visualization\n",
    "posts_df.to_csv('languagetechnology.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now coming back to add indexes and triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://kg37m:***@pgsql.dsa.lan/dsa_student\n",
      "Done.\n",
      "2480 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "-------------------------\n",
    "-- Separate Ts_Vector column\n",
    "-------------------------\n",
    "-- TS_Vector for GIN INDEX\n",
    "ALTER TABLE posts\n",
    "  ADD COLUMN text_tsv_gin tsvector;\n",
    "\n",
    "UPDATE posts\n",
    "SET text_tsv_gin = to_tsvector('pg_catalog.english', text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://kg37m:***@pgsql.dsa.lan/dsa_student\n",
      "Done.\n",
      "2480 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "-- TS_Vector for GIST INDEX\n",
    "ALTER TABLE posts\n",
    "  ADD COLUMN text_tsv_gist tsvector;\n",
    "\n",
    "UPDATE posts\n",
    "SET text_tsv_gist = to_tsvector('pg_catalog.english', text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://kg37m:***@pgsql.dsa.lan/dsa_student\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "-- Add triggers\n",
    "\n",
    "CREATE TRIGGER tsv_gin_update \n",
    "\tBEFORE INSERT OR UPDATE\n",
    "\tON posts \n",
    "\tFOR EACH ROW \n",
    "\tEXECUTE PROCEDURE \n",
    "\ttsvector_update_trigger(line_tsv_gin,'pg_catalog.english',text);\n",
    "\n",
    "CREATE TRIGGER tsv_gist_update \n",
    "\tBEFORE INSERT OR UPDATE\n",
    "\tON posts \n",
    "\tFOR EACH \n",
    "\tROW EXECUTE PROCEDURE\n",
    "\ttsvector_update_trigger(line_tsv_gist,'pg_catalog.english',text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://kg37m:***@pgsql.dsa.lan/dsa_student\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "-- Add indexes\n",
    "\n",
    "CREATE INDEX posts_text\n",
    "ON posts USING GIN(text gin_trgm_ops);\n",
    "\n",
    "-- GIN INDEX on content_tsv_gin\n",
    "CREATE INDEX posts_text_tsv_gin\n",
    "ON posts USING GIN(text_tsv_gin);\n",
    "\n",
    "-- GIST INDEX on content_tsv_gist\n",
    "CREATE INDEX posts_text_tsv_gist\n",
    "ON posts USING GIST(text_tsv_gist);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### In part II, we will search your database as `dsa_ro_user user`. To prepare your DB to be read, you will need to grant the dsa_ro_user schema access and select privileges on your table.\n",
    "\n",
    "```SQL\n",
    "GRANT USAGE ON SCHEMA <your schema> TO dsa_ro_user;  -- NOTE: change to your schema\n",
    "GRANT SELECT ON <your table> TO dsa_ro_user;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://kg37m:***@pgsql.dsa.lan/dsa_student\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "GRANT USAGE ON SCHEMA kg37m TO dsa_ro_user;\n",
    "GRANT SELECT ON posts TO dsa_ro_user;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
